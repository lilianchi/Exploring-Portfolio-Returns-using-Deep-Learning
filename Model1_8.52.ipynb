{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NcDhtxLCV8Tw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, LayerNormalization, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "vI12F-E9V8T1",
    "outputId": "869138a1-ef3d-4c37-86c8-e408129de90a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Z_eff = pd.read_csv('data_Z_eff.csv',header=None)\n",
    "R_eff = pd.read_csv('data_R_eff.csv',header = None)\n",
    "R_org_eff = pd.read_csv('data_R_org_eff.csv',header = None)\n",
    "group_ind = pd.read_csv('data_group_ind.csv',header =None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.605691</td>\n",
       "      <td>0.183234</td>\n",
       "      <td>-0.733577</td>\n",
       "      <td>-0.452301</td>\n",
       "      <td>0.693095</td>\n",
       "      <td>0.766010</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.602862</td>\n",
       "      <td>0.885659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660839</td>\n",
       "      <td>-0.442308</td>\n",
       "      <td>0.919580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.497942</td>\n",
       "      <td>-0.464286</td>\n",
       "      <td>0.290173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.087398</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>0.251825</td>\n",
       "      <td>-0.005612</td>\n",
       "      <td>-0.148338</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.617174</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099650</td>\n",
       "      <td>-0.795455</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.268591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.171468</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.003468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.508130</td>\n",
       "      <td>-0.147305</td>\n",
       "      <td>0.251825</td>\n",
       "      <td>-0.095398</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>-0.307882</td>\n",
       "      <td>-0.269321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.577818</td>\n",
       "      <td>-0.294574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833916</td>\n",
       "      <td>-0.026224</td>\n",
       "      <td>-0.277972</td>\n",
       "      <td>0.707787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.410151</td>\n",
       "      <td>0.150510</td>\n",
       "      <td>-0.193064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.178667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.930894</td>\n",
       "      <td>-0.822754</td>\n",
       "      <td>0.251825</td>\n",
       "      <td>-0.696970</td>\n",
       "      <td>0.501279</td>\n",
       "      <td>-0.906404</td>\n",
       "      <td>-0.655738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.937388</td>\n",
       "      <td>-0.193798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.622378</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>-0.601399</td>\n",
       "      <td>0.055118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.883402</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.787283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.193708</td>\n",
       "      <td>-0.547305</td>\n",
       "      <td>0.181212</td>\n",
       "      <td>-0.167228</td>\n",
       "      <td>0.961637</td>\n",
       "      <td>-0.167488</td>\n",
       "      <td>0.042155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.568873</td>\n",
       "      <td>0.286822</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.959790</td>\n",
       "      <td>-0.026224</td>\n",
       "      <td>-0.277972</td>\n",
       "      <td>0.707787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.670782</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>-0.412717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.178667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219311</th>\n",
       "      <td>0.288483</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>-0.123140</td>\n",
       "      <td>0.452809</td>\n",
       "      <td>0.864931</td>\n",
       "      <td>0.017188</td>\n",
       "      <td>-0.000822</td>\n",
       "      <td>-0.222944</td>\n",
       "      <td>0.729479</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094673</td>\n",
       "      <td>0.938588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851568</td>\n",
       "      <td>0.785146</td>\n",
       "      <td>-0.248915</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.839611</td>\n",
       "      <td>0.592838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219312</th>\n",
       "      <td>0.244607</td>\n",
       "      <td>-0.191131</td>\n",
       "      <td>-0.123140</td>\n",
       "      <td>-0.378652</td>\n",
       "      <td>0.099268</td>\n",
       "      <td>-0.528427</td>\n",
       "      <td>-0.251130</td>\n",
       "      <td>0.487013</td>\n",
       "      <td>-0.051392</td>\n",
       "      <td>-0.511804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580590</td>\n",
       "      <td>0.938588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491289</td>\n",
       "      <td>-0.527188</td>\n",
       "      <td>-0.248915</td>\n",
       "      <td>0.122846</td>\n",
       "      <td>0.700284</td>\n",
       "      <td>-0.953289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219313</th>\n",
       "      <td>-0.101280</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>-0.123140</td>\n",
       "      <td>0.267416</td>\n",
       "      <td>0.112286</td>\n",
       "      <td>0.017188</td>\n",
       "      <td>-0.000822</td>\n",
       "      <td>0.570707</td>\n",
       "      <td>0.518915</td>\n",
       "      <td>-0.890388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.493044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>-0.361775</td>\n",
       "      <td>0.020209</td>\n",
       "      <td>-0.327586</td>\n",
       "      <td>-0.687410</td>\n",
       "      <td>-0.052439</td>\n",
       "      <td>-0.982179</td>\n",
       "      <td>0.824056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219314</th>\n",
       "      <td>0.329433</td>\n",
       "      <td>0.744648</td>\n",
       "      <td>0.349794</td>\n",
       "      <td>0.501685</td>\n",
       "      <td>0.084622</td>\n",
       "      <td>0.195240</td>\n",
       "      <td>-0.476367</td>\n",
       "      <td>-0.398990</td>\n",
       "      <td>-0.118487</td>\n",
       "      <td>-0.561551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417034</td>\n",
       "      <td>0.035142</td>\n",
       "      <td>0.236177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491289</td>\n",
       "      <td>0.218833</td>\n",
       "      <td>0.156295</td>\n",
       "      <td>0.287862</td>\n",
       "      <td>0.594978</td>\n",
       "      <td>-0.745426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219315</th>\n",
       "      <td>-0.398172</td>\n",
       "      <td>-0.819572</td>\n",
       "      <td>0.349794</td>\n",
       "      <td>-0.008427</td>\n",
       "      <td>0.585842</td>\n",
       "      <td>0.095637</td>\n",
       "      <td>0.237978</td>\n",
       "      <td>-0.948773</td>\n",
       "      <td>0.807281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.929420</td>\n",
       "      <td>0.938588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851568</td>\n",
       "      <td>-0.360080</td>\n",
       "      <td>-0.066570</td>\n",
       "      <td>-0.193986</td>\n",
       "      <td>-0.696233</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2219316 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6   \\\n",
       "0        0.605691  0.183234 -0.733577 -0.452301  0.693095  0.766010  0.934426   \n",
       "1       -0.087398  0.007186  0.251825 -0.005612 -0.148338  0.008621  0.002342   \n",
       "2        0.508130 -0.147305  0.251825 -0.095398  0.941176 -0.307882 -0.269321   \n",
       "3       -0.930894 -0.822754  0.251825 -0.696970  0.501279 -0.906404 -0.655738   \n",
       "4       -0.193708 -0.547305  0.181212 -0.167228  0.961637 -0.167488  0.042155   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "2219311  0.288483  0.001147 -0.123140  0.452809  0.864931  0.017188 -0.000822   \n",
       "2219312  0.244607 -0.191131 -0.123140 -0.378652  0.099268 -0.528427 -0.251130   \n",
       "2219313 -0.101280  0.001147 -0.123140  0.267416  0.112286  0.017188 -0.000822   \n",
       "2219314  0.329433  0.744648  0.349794  0.501685  0.084622  0.195240 -0.476367   \n",
       "2219315 -0.398172 -0.819572  0.349794 -0.008427  0.585842  0.095637  0.237978   \n",
       "\n",
       "               7         8         9   ...        54        55        56  \\\n",
       "0        0.000000 -0.602862  0.885659  ... -0.660839 -0.442308  0.919580   \n",
       "1        0.000000 -0.617174  0.844961  ... -0.099650 -0.795455  0.673077   \n",
       "2        0.000000 -0.577818 -0.294574  ... -0.833916 -0.026224 -0.277972   \n",
       "3        0.000000 -0.937388 -0.193798  ... -0.622378  0.454545 -0.601399   \n",
       "4        0.000000 -0.568873  0.286822  ... -0.959790 -0.026224 -0.277972   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "2219311 -0.222944  0.729479  0.004637  ...  0.094673  0.938588  1.000000   \n",
       "2219312  0.487013 -0.051392 -0.511804  ...  0.580590  0.938588  1.000000   \n",
       "2219313  0.570707  0.518915 -0.890388  ... -0.493044  1.000000  0.070307   \n",
       "2219314 -0.398990 -0.118487 -0.561551  ...  0.417034  0.035142  0.236177   \n",
       "2219315 -0.948773  0.807281  1.000000  ... -0.929420  0.938588  1.000000   \n",
       "\n",
       "               57        58        59        60        61        62        63  \n",
       "0        1.000000  0.000000 -0.497942 -0.464286  0.290173  0.000000 -0.008000  \n",
       "1        0.268591  0.000000 -0.171468 -0.250000 -0.003468  0.000000 -0.008000  \n",
       "2        0.707787  0.000000 -0.410151  0.150510 -0.193064  0.000000 -0.178667  \n",
       "3        0.055118  0.000000 -0.883402 -0.250000 -0.787283  0.000000 -0.008000  \n",
       "4        0.707787  0.000000 -0.670782 -0.214286 -0.412717  0.000000 -0.178667  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "2219311  1.000000  0.851568  0.785146 -0.248915  0.004034  0.839611  0.592838  \n",
       "2219312  1.000000  0.491289 -0.527188 -0.248915  0.122846  0.700284 -0.953289  \n",
       "2219313 -0.361775  0.020209 -0.327586 -0.687410 -0.052439 -0.982179  0.824056  \n",
       "2219314  1.000000  0.491289  0.218833  0.156295  0.287862  0.594978 -0.745426  \n",
       "2219315  1.000000  0.851568 -0.360080 -0.066570 -0.193986 -0.696233  1.000000  \n",
       "\n",
       "[2219316 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.045149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.094038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.016267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219311</th>\n",
       "      <td>0.091533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219312</th>\n",
       "      <td>0.142735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219313</th>\n",
       "      <td>0.109201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219314</th>\n",
       "      <td>0.075775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219315</th>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2219316 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0       -0.045149\n",
       "1       -0.094038\n",
       "2       -0.016267\n",
       "3        0.000012\n",
       "4        0.023208\n",
       "...           ...\n",
       "2219311  0.091533\n",
       "2219312  0.142735\n",
       "2219313  0.109201\n",
       "2219314  0.075775\n",
       "2219315  0.200000\n",
       "\n",
       "[2219316 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.045149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.094038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.016267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219311</th>\n",
       "      <td>0.091533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219312</th>\n",
       "      <td>0.142735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219313</th>\n",
       "      <td>0.109201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219314</th>\n",
       "      <td>0.075775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219315</th>\n",
       "      <td>0.242788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2219316 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0       -0.045149\n",
       "1       -0.094038\n",
       "2       -0.016267\n",
       "3        0.000012\n",
       "4        0.023208\n",
       "...           ...\n",
       "2219311  0.091533\n",
       "2219312  0.142735\n",
       "2219313  0.109201\n",
       "2219314  0.075775\n",
       "2219315  0.242788\n",
       "\n",
       "[2219316 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# time VS. feature\n",
    "display(Z_eff)\n",
    "\n",
    "# return rate\n",
    "# truncated from R-org_eff. used for training and validation\n",
    "display(R_eff)\n",
    "\n",
    "# real-world data\n",
    "display(R_org_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>2207726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>2210541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>2213366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>2216313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>2219316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0          0\n",
       "1       1138\n",
       "2       2281\n",
       "3       3425\n",
       "4       4571\n",
       "..       ...\n",
       "686  2207726\n",
       "687  2210541\n",
       "688  2213366\n",
       "689  2216313\n",
       "690  2219316\n",
       "\n",
       "[691 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# monthly record, total 690 months\n",
    "# 0~1137：t0 (m0)，0~1137 stock active\n",
    "# 1138~2280：t1 (m1)，1138~2280 stock active\n",
    "display(group_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Psf8guRAV8T1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training 120月(10年)、valid 60月(5年)、test 12月(1年) 為一循環，去跑這690個月(約58年)的data。\n",
    "# 第一次從第一年開始，跑16年，第二次從第二年開始，跑16年，以此類推...\n",
    "# 總共跑42次循環\n",
    "\n",
    "t_train_start = list(range(0,41*12+1,12))\n",
    "t_train_end =[x+120 for x in t_train_start]\n",
    "t_val_start= [x for x in t_train_end]\n",
    "t_val_end = [x+60 for x in t_val_start]\n",
    "t_test_start = [x for x in t_val_end]\n",
    "t_test_end = [x+12 for x in t_test_start]\n",
    "t_test_end[41]=678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IaLdT9DqV8T2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_start = group_ind.iloc[t_train_start][0].to_list()\n",
    "train_end = group_ind.iloc[t_train_end][0].to_list()\n",
    "test_start = group_ind.iloc[t_test_start][0].to_list()\n",
    "test_end = group_ind.iloc[t_test_end][0].to_list()\n",
    "val_start = group_ind.iloc[t_val_start][0].to_list()\n",
    "val_end = group_ind.iloc[t_val_end][0].to_list()                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 13982,\n",
       " 29160,\n",
       " 45643,\n",
       " 63036,\n",
       " 82747,\n",
       " 104359,\n",
       " 126950,\n",
       " 149730,\n",
       " 173744,\n",
       " 205530,\n",
       " 238201,\n",
       " 266213,\n",
       " 297905,\n",
       " 331270,\n",
       " 366436,\n",
       " 403001,\n",
       " 439798,\n",
       " 479825,\n",
       " 519039,\n",
       " 560151,\n",
       " 606230,\n",
       " 649583,\n",
       " 693694,\n",
       " 740493,\n",
       " 785023,\n",
       " 827350,\n",
       " 868091,\n",
       " 905534,\n",
       " 948816,\n",
       " 997587,\n",
       " 1054105,\n",
       " 1112321,\n",
       " 1176013,\n",
       " 1242410,\n",
       " 1309280,\n",
       " 1368589,\n",
       " 1427683,\n",
       " 1478335,\n",
       " 1523159,\n",
       " 1563174,\n",
       " 1608972]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portf_ret(preds, y_org):\n",
    "    list_buy = [idx for idx, val in preds if val > np.percentile(preds,90)]\n",
    "    list_buy = [idx for idx, val in preds if val < np.percentile(preds,10)]\n",
    "    portf_ret_t = np.mean(y_true_t[list_buy]) - np.mean(y_true_t[list_sell])\n",
    "    return portf_ret_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_pred_val = []\n",
    "y_pred_test = []\n",
    "loss = []\n",
    "model_list = []\n",
    "y_org = []\n",
    "y_org_val = []\n",
    "y_org_test = []\n",
    "y_reff = []\n",
    "y_reff_val = []\n",
    "y_reff_test = []\n",
    "portf_ret_nn_test = []\n",
    "R_pred=R_org_eff\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "803/803 [==============================] - 21s 24ms/step - loss: 0.0315 - val_loss: 0.0112\n",
      "Epoch 2/50\n",
      "803/803 [==============================] - 19s 24ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 3/50\n",
      "803/803 [==============================] - 20s 25ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 4/50\n",
      "803/803 [==============================] - 22s 27ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 5/50\n",
      "803/803 [==============================] - 22s 28ms/step - loss: 0.0085 - val_loss: 0.0097\n",
      "Epoch 6/50\n",
      "803/803 [==============================] - 22s 27ms/step - loss: 0.0085 - val_loss: 0.0097\n",
      "Epoch 7/50\n",
      "803/803 [==============================] - 22s 27ms/step - loss: 0.0084 - val_loss: 0.0095\n",
      "Epoch 8/50\n",
      "803/803 [==============================] - 22s 27ms/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 9/50\n",
      "803/803 [==============================] - 22s 27ms/step - loss: 0.0082 - val_loss: 0.0097\n",
      "Epoch 10/50\n",
      "803/803 [==============================] - 22s 27ms/step - loss: 0.0081 - val_loss: 0.0101\n",
      "Epoch 11/50\n",
      "803/803 [==============================] - 22s 28ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 12/50\n",
      "803/803 [==============================] - 22s 28ms/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 00012: early stopping\n",
      "180 0 3098 3098 310 310\n",
      "181 3098 6277 3179 318 318\n",
      "182 6277 9463 3186 319 319\n",
      "183 9463 12393 2930 293 293\n",
      "184 12393 15350 2957 289 296\n",
      "185 15350 18302 2952 296 296\n",
      "186 18302 21339 3037 304 304\n",
      "187 21339 24325 2986 299 299\n",
      "188 24325 27362 3037 304 304\n",
      "189 27362 30431 3069 307 307\n",
      "190 30431 33491 3060 306 306\n",
      "191 33491 36565 3074 299 308\n",
      "Epoch 1/50\n",
      "876/876 [==============================] - 26s 28ms/step - loss: 0.0358 - val_loss: 0.0096\n",
      "Epoch 2/50\n",
      "876/876 [==============================] - 24s 27ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 3/50\n",
      "876/876 [==============================] - 25s 29ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 4/50\n",
      "876/876 [==============================] - 26s 30ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "Epoch 5/50\n",
      "876/876 [==============================] - 28s 32ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 6/50\n",
      "876/876 [==============================] - 32s 36ms/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 7/50\n",
      "876/876 [==============================] - 37s 43ms/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 8/50\n",
      "876/876 [==============================] - 23s 26ms/step - loss: 0.0090 - val_loss: 0.0103\n",
      "Epoch 00008: early stopping\n",
      "192 0 3074 3074 205 308\n",
      "193 3074 6202 3128 192 313\n",
      "194 6202 9315 3113 52 312\n",
      "195 9315 12316 3001 130 300\n",
      "196 12316 15346 3030 195 303\n",
      "197 15346 18438 3092 277 310\n",
      "198 18438 21610 3172 202 318\n",
      "199 21610 24772 3162 83 317\n",
      "200 24772 27728 2956 184 296\n",
      "201 27728 30701 2973 208 298\n",
      "202 30701 33730 3029 139 303\n",
      "203 33730 36797 3067 150 307\n",
      "Epoch 1/50\n",
      "926/926 [==============================] - 27s 27ms/step - loss: 0.2591 - val_loss: 0.0118\n",
      "Epoch 2/50\n",
      "926/926 [==============================] - 26s 28ms/step - loss: 0.0114 - val_loss: 0.0094\n",
      "Epoch 3/50\n",
      "926/926 [==============================] - 26s 28ms/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 4/50\n",
      "926/926 [==============================] - 29s 32ms/step - loss: 0.0104 - val_loss: 0.0087\n",
      "Epoch 5/50\n",
      "926/926 [==============================] - 33s 36ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 6/50\n",
      "926/926 [==============================] - 35s 37ms/step - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 7/50\n",
      "926/926 [==============================] - 40s 43ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 8/50\n",
      "926/926 [==============================] - 24s 26ms/step - loss: 0.0099 - val_loss: 0.0090\n",
      "Epoch 9/50\n",
      "926/926 [==============================] - 25s 27ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 00009: early stopping\n",
      "204 0 3149 3149 315 315\n",
      "205 3149 6364 3215 322 322\n",
      "206 6364 9630 3266 327 327\n",
      "207 9630 12932 3302 331 331\n",
      "208 12932 16281 3349 335 243\n",
      "209 16281 19615 3334 334 334\n",
      "210 19615 22955 3340 334 334\n",
      "211 22955 26276 3321 332 332\n",
      "212 26276 29662 3386 339 339\n",
      "213 29662 33100 3438 344 344\n",
      "214 33100 36567 3467 347 347\n",
      "215 36567 40027 3460 346 346\n",
      "Epoch 1/50\n",
      "986/986 [==============================] - 28s 27ms/step - loss: 0.2176 - val_loss: 0.0178\n",
      "Epoch 2/50\n",
      "986/986 [==============================] - 28s 29ms/step - loss: 0.0139 - val_loss: 0.0104\n",
      "Epoch 3/50\n",
      "986/986 [==============================] - 30s 30ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "986/986 [==============================] - 33s 33ms/step - loss: 0.0107 - val_loss: 0.0089\n",
      "Epoch 5/50\n",
      "986/986 [==============================] - 41s 42ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 6/50\n",
      "986/986 [==============================] - 33s 34ms/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 7/50\n",
      "986/986 [==============================] - 26s 27ms/step - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 8/50\n",
      "986/986 [==============================] - 27s 27ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 9/50\n",
      "986/986 [==============================] - 27s 27ms/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 10/50\n",
      "986/986 [==============================] - 28s 29ms/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 11/50\n",
      "986/986 [==============================] - 30s 30ms/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 12/50\n",
      "986/986 [==============================] - 33s 34ms/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 13/50\n",
      "986/986 [==============================] - 44s 45ms/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 14/50\n",
      "986/986 [==============================] - 30s 31ms/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 15/50\n",
      "986/986 [==============================] - 26s 27ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 00015: early stopping\n",
      "216 0 3449 3449 345 174\n",
      "217 3449 6813 3364 337 218\n",
      "218 6813 10043 3230 323 209\n",
      "219 10043 13353 3310 331 212\n",
      "220 13353 16679 3326 333 212\n",
      "221 16679 19974 3295 330 234\n",
      "222 19974 23254 3280 328 242\n",
      "223 23254 26479 3225 323 253\n",
      "224 26479 29666 3187 319 271\n",
      "225 29666 32887 3221 322 266\n",
      "226 32887 36085 3198 320 320\n",
      "227 36085 39214 3129 313 291\n",
      "Epoch 1/50\n",
      "1048/1048 [==============================] - 31s 28ms/step - loss: 0.0358 - val_loss: 0.0102\n",
      "Epoch 2/50\n",
      "1048/1048 [==============================] - 30s 29ms/step - loss: 0.0102 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "1048/1048 [==============================] - 31s 30ms/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 4/50\n",
      "1048/1048 [==============================] - 36s 35ms/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 5/50\n",
      "1048/1048 [==============================] - 41s 39ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 6/50\n",
      "1048/1048 [==============================] - 41s 39ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 7/50\n",
      "1048/1048 [==============================] - 28s 27ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 8/50\n",
      "1048/1048 [==============================] - 29s 28ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 9/50\n",
      "1048/1048 [==============================] - 30s 29ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 10/50\n",
      "1048/1048 [==============================] - 33s 31ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 11/50\n",
      "1048/1048 [==============================] - 37s 35ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 12/50\n",
      "1048/1048 [==============================] - 63s 61ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 13/50\n",
      "1048/1048 [==============================] - 32s 31ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 14/50\n",
      "1048/1048 [==============================] - 28s 27ms/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 15/50\n",
      "1048/1048 [==============================] - 28s 27ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 16/50\n",
      "1048/1048 [==============================] - 30s 28ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 17/50\n",
      "1048/1048 [==============================] - 32s 30ms/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 18/50\n",
      "1048/1048 [==============================] - 36s 34ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 19/50\n",
      "1048/1048 [==============================] - 47s 44ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 20/50\n",
      "1048/1048 [==============================] - 27s 26ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 21/50\n",
      "1048/1048 [==============================] - 28s 27ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 00021: early stopping\n",
      "228 0 3101 3101 0 310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilian\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\lilian\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229 3101 6228 3127 0 313\n",
      "230 6228 9362 3134 1 314\n",
      "231 9362 12604 3242 0 325\n",
      "232 12604 15947 3343 0 335\n",
      "233 15947 19322 3375 0 338\n",
      "234 19322 22772 3450 0 345\n",
      "235 22772 26292 3520 0 352\n",
      "236 26292 29864 3572 1 358\n",
      "237 29864 33507 3643 1 365\n",
      "238 33507 37261 3754 0 376\n",
      "239 37261 41112 3851 2 385\n",
      "Epoch 1/50\n",
      "1109/1109 [==============================] - 31s 27ms/step - loss: 0.1949 - val_loss: 0.0133\n",
      "Epoch 2/50\n",
      "1109/1109 [==============================] - 31s 28ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 3/50\n",
      "1109/1109 [==============================] - 33s 30ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 4/50\n",
      "1109/1109 [==============================] - 38s 34ms/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 5/50\n",
      "1109/1109 [==============================] - 46s 42ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 6/50\n",
      "1109/1109 [==============================] - 29s 26ms/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 7/50\n",
      "1109/1109 [==============================] - 30s 27ms/step - loss: 0.0091 - val_loss: 0.0102\n",
      "Epoch 8/50\n",
      "1109/1109 [==============================] - 29s 27ms/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 9/50\n",
      "1109/1109 [==============================] - 31s 28ms/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 10/50\n",
      "1109/1109 [==============================] - 33s 29ms/step - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 11/50\n",
      "1109/1109 [==============================] - 37s 33ms/step - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 12/50\n",
      "1109/1109 [==============================] - 48s 43ms/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 13/50\n",
      "1109/1109 [==============================] - 33s 30ms/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 14/50\n",
      "1109/1109 [==============================] - 30s 27ms/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 15/50\n",
      "1109/1109 [==============================] - 30s 27ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 16/50\n",
      "1109/1109 [==============================] - 31s 28ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 00016: early stopping\n",
      "240 0 3869 3869 387 387\n",
      "241 3869 7736 3867 387 387\n",
      "242 7736 11604 3868 387 387\n",
      "243 11604 15431 3827 383 383\n",
      "244 15431 19314 3883 389 389\n",
      "245 19314 23215 3901 390 390\n",
      "246 23215 27142 3927 393 393\n",
      "247 27142 31000 3858 386 386\n",
      "248 31000 34857 3857 386 386\n",
      "249 34857 38645 3788 379 379\n",
      "250 38645 42361 3716 372 372\n",
      "251 42361 46079 3718 372 372\n",
      "Epoch 1/50\n",
      "1167/1167 [==============================] - 37s 30ms/step - loss: 0.1107 - val_loss: 0.0109\n",
      "Epoch 2/50\n",
      "1167/1167 [==============================] - 38s 33ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 3/50\n",
      "1167/1167 [==============================] - 51s 43ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 4/50\n",
      "1167/1167 [==============================] - 32s 28ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 5/50\n",
      "1167/1167 [==============================] - 32s 27ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 6/50\n",
      "1167/1167 [==============================] - 32s 28ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 7/50\n",
      "1167/1167 [==============================] - 34s 29ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 8/50\n",
      "1167/1167 [==============================] - 36s 31ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 9/50\n",
      "1167/1167 [==============================] - 40s 34ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 10/50\n",
      "1167/1167 [==============================] - 49s 42ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 11/50\n",
      "1167/1167 [==============================] - 31s 27ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 12/50\n",
      "1167/1167 [==============================] - 32s 28ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 00012: early stopping\n",
      "252 0 3616 3616 362 124\n",
      "253 3616 7317 3701 370 188\n",
      "254 7317 10980 3663 367 163\n",
      "255 10980 14594 3614 362 161\n",
      "256 14594 18125 3531 353 238\n",
      "257 18125 21640 3515 352 213\n",
      "258 21640 25298 3658 366 167\n",
      "259 25298 28970 3672 368 244\n",
      "260 28970 32613 3643 365 202\n",
      "261 32613 36213 3600 360 206\n",
      "262 36213 39790 3577 358 183\n",
      "263 39790 43353 3563 357 187\n",
      "Epoch 1/50\n",
      "1223/1223 [==============================] - 35s 27ms/step - loss: 0.2403 - val_loss: 0.0108\n",
      "Epoch 2/50\n",
      "1223/1223 [==============================] - 35s 28ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "1223/1223 [==============================] - 37s 30ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 4/50\n",
      "1223/1223 [==============================] - 42s 34ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 5/50\n",
      "1223/1223 [==============================] - 47s 39ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 6/50\n",
      "1223/1223 [==============================] - 32s 26ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 7/50\n",
      "1223/1223 [==============================] - 33s 27ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 8/50\n",
      "1223/1223 [==============================] - 33s 27ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 9/50\n",
      "1223/1223 [==============================] - 35s 29ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 10/50\n",
      "1223/1223 [==============================] - 38s 31ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 11/50\n",
      "1223/1223 [==============================] - 44s 36ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 12/50\n",
      "1223/1223 [==============================] - 43s 36ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 13/50\n",
      "1223/1223 [==============================] - 32s 27ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 14/50\n",
      "1223/1223 [==============================] - 33s 27ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 15/50\n",
      "1223/1223 [==============================] - 33s 27ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 00015: early stopping\n",
      "264 0 3597 3597 360 360\n",
      "265 3597 7182 3585 359 359\n",
      "266 7182 10704 3522 353 353\n",
      "267 10704 14237 3533 354 354\n",
      "268 14237 17825 3588 359 359\n",
      "269 17825 21445 3620 362 362\n",
      "270 21445 25114 3669 367 367\n",
      "271 25114 28816 3702 371 371\n",
      "272 28816 32577 3761 376 376\n",
      "273 32577 36360 3783 379 379\n",
      "274 36360 40211 3851 385 385\n",
      "275 40211 44111 3900 390 390\n",
      "Epoch 1/50\n",
      "1290/1290 [==============================] - 42s 31ms/step - loss: 0.0399 - val_loss: 0.0100\n",
      "Epoch 2/50\n",
      "1290/1290 [==============================] - 49s 38ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 3/50\n",
      "1290/1290 [==============================] - 34s 26ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "1290/1290 [==============================] - 34s 27ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 5/50\n",
      "1290/1290 [==============================] - 34s 27ms/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 6/50\n",
      "1290/1290 [==============================] - 35s 27ms/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 7/50\n",
      "1290/1290 [==============================] - 37s 29ms/step - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 8/50\n",
      "1290/1290 [==============================] - 42s 32ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 9/50\n",
      "1290/1290 [==============================] - 53s 41ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 00009: early stopping\n",
      "276 0 3823 3823 383 383\n",
      "277 3823 7645 3822 383 383\n",
      "278 7645 11416 3771 377 377\n",
      "279 11416 15231 3815 382 382\n",
      "280 15231 19052 3821 382 382\n",
      "281 19052 22810 3758 376 376\n",
      "282 22810 26676 3866 387 387\n",
      "283 26676 30652 3976 398 398\n",
      "284 30652 34684 4032 404 404\n",
      "285 34684 38697 4013 402 402\n",
      "286 38697 42714 4017 402 402\n",
      "287 42714 46799 4085 409 409\n",
      "Epoch 1/50\n",
      "1349/1349 [==============================] - 37s 27ms/step - loss: 0.1063 - val_loss: 0.0114\n",
      "Epoch 2/50\n",
      "1349/1349 [==============================] - 37s 27ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 3/50\n",
      "1349/1349 [==============================] - 37s 27ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 4/50\n",
      "1349/1349 [==============================] - 39s 29ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 5/50\n",
      "1349/1349 [==============================] - 43s 32ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 6/50\n",
      "1349/1349 [==============================] - 54s 40ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 7/50\n",
      "1349/1349 [==============================] - 38s 28ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 8/50\n",
      "1349/1349 [==============================] - 37s 28ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 9/50\n",
      "1349/1349 [==============================] - 37s 27ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 00009: early stopping\n",
      "288 0 4122 4122 413 413\n",
      "289 4122 8256 4134 414 414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290 8256 12398 4142 415 415\n",
      "291 12398 15988 3590 359 359\n",
      "292 15988 19420 3432 316 344\n",
      "293 19420 22873 3453 346 346\n",
      "294 22873 26404 3531 353 353\n",
      "295 26404 30000 3596 360 360\n",
      "296 30000 33650 3650 365 365\n",
      "297 33650 37287 3637 364 364\n",
      "298 37287 40878 3591 359 359\n",
      "299 40878 44530 3652 366 366\n",
      "Epoch 1/50\n",
      "1386/1386 [==============================] - 44s 30ms/step - loss: 0.1266 - val_loss: 0.0167\n",
      "Epoch 2/50\n",
      "1386/1386 [==============================] - 47s 34ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 3/50\n",
      "1386/1386 [==============================] - 48s 35ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 4/50\n",
      "1386/1386 [==============================] - 37s 27ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 5/50\n",
      "1386/1386 [==============================] - 38s 28ms/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 6/50\n",
      "1386/1386 [==============================] - 40s 29ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 7/50\n",
      "1386/1386 [==============================] - 43s 31ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 8/50\n",
      "1386/1386 [==============================] - 54s 39ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 9/50\n",
      "1386/1386 [==============================] - 38s 28ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 10/50\n",
      "1386/1386 [==============================] - 37s 27ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 11/50\n",
      "1386/1386 [==============================] - 38s 27ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 12/50\n",
      "1386/1386 [==============================] - 41s 29ms/step - loss: 0.0092 - val_loss: 0.0099\n",
      "Epoch 00012: early stopping\n",
      "300 0 3637 3637 364 364\n",
      "301 3637 7220 3583 359 359\n",
      "302 7220 10791 3571 357 357\n",
      "303 10791 14322 3531 353 353\n",
      "304 14322 17783 3461 346 346\n",
      "305 17783 21250 3467 347 347\n",
      "306 21250 24750 3500 350 350\n",
      "307 24750 28241 3491 349 349\n",
      "308 28241 31759 3518 352 352\n",
      "309 31759 35284 3525 353 353\n",
      "310 35284 38822 3538 354 354\n",
      "311 38822 42327 3505 351 351\n",
      "Epoch 1/50\n",
      "1438/1438 [==============================] - 49s 33ms/step - loss: 0.0710 - val_loss: 0.0116\n",
      "Epoch 2/50\n",
      "1438/1438 [==============================] - 54s 37ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 3/50\n",
      "1438/1438 [==============================] - 37s 26ms/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 4/50\n",
      "1438/1438 [==============================] - 38s 26ms/step - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 5/50\n",
      "1438/1438 [==============================] - 39s 27ms/step - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 6/50\n",
      "1438/1438 [==============================] - 42s 29ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 7/50\n",
      "1438/1438 [==============================] - 46s 32ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 8/50\n",
      "1438/1438 [==============================] - 53s 37ms/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 9/50\n",
      "1438/1438 [==============================] - 38s 26ms/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 10/50\n",
      "1438/1438 [==============================] - 38s 27ms/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 00010: early stopping\n",
      "312 0 3532 3532 354 354\n",
      "313 3532 7047 3515 352 352\n",
      "314 7047 10574 3527 353 352\n",
      "315 10574 14009 3435 344 344\n",
      "316 14009 17424 3415 342 342\n",
      "317 17424 20835 3411 341 341\n",
      "318 20835 24132 3297 330 330\n",
      "319 24132 27428 3296 330 330\n",
      "320 27428 30759 3331 333 333\n",
      "321 30759 34040 3281 328 328\n",
      "322 34040 37378 3338 334 334\n",
      "323 37378 40741 3363 337 337\n",
      "Epoch 1/50\n",
      "1498/1498 [==============================] - 41s 26ms/step - loss: 0.0428 - val_loss: 0.0090\n",
      "Epoch 2/50\n",
      "1498/1498 [==============================] - 42s 28ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 3/50\n",
      "1498/1498 [==============================] - 45s 30ms/step - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 4/50\n",
      "1498/1498 [==============================] - 57s 38ms/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 5/50\n",
      "1498/1498 [==============================] - 39s 26ms/step - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 6/50\n",
      "1498/1498 [==============================] - 39s 26ms/step - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 7/50\n",
      "1498/1498 [==============================] - 40s 26ms/step - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 8/50\n",
      "1498/1498 [==============================] - 43s 28ms/step - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 00008: early stopping\n",
      "324 0 3309 3309 331 1\n",
      "325 3309 6462 3153 316 1\n",
      "326 6462 9471 3009 301 3\n",
      "327 9471 12353 2882 289 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilian\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\lilian\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 12353 15257 2904 291 0\n",
      "329 15257 18144 2887 289 0\n",
      "330 18144 21115 2971 297 0\n",
      "331 21115 24267 3152 316 0\n",
      "332 24267 27504 3237 324 2\n",
      "333 27504 30795 3291 329 2\n",
      "334 30795 34125 3330 333 0\n",
      "335 34125 37443 3318 332 0\n",
      "Epoch 1/50\n",
      "1547/1547 [==============================] - 53s 33ms/step - loss: 0.1932 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "1547/1547 [==============================] - 51s 33ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 3/50\n",
      "1547/1547 [==============================] - 40s 26ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "1547/1547 [==============================] - 41s 26ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 5/50\n",
      "1547/1547 [==============================] - 41s 27ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 6/50\n",
      "1547/1547 [==============================] - 45s 29ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 7/50\n",
      "1547/1547 [==============================] - 51s 33ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 8/50\n",
      "1547/1547 [==============================] - 50s 32ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 00008: early stopping\n",
      "336 0 3360 3360 336 336\n",
      "337 3360 6759 3399 340 340\n",
      "338 6759 10161 3402 341 341\n",
      "339 10161 13601 3440 344 344\n",
      "340 13601 17059 3458 346 346\n",
      "341 17059 20559 3500 350 350\n",
      "342 20559 24260 3701 370 370\n",
      "343 24260 28047 3787 379 379\n",
      "344 28047 31880 3833 384 384\n",
      "345 31880 35679 3799 380 380\n",
      "346 35679 39511 3832 384 384\n",
      "347 39511 43282 3771 377 377\n",
      "Epoch 1/50\n",
      "1599/1599 [==============================] - 43s 26ms/step - loss: 0.0682 - val_loss: 0.0097\n",
      "Epoch 2/50\n",
      "1599/1599 [==============================] - 41s 26ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 3/50\n",
      "1599/1599 [==============================] - 44s 27ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "1599/1599 [==============================] - 47s 29ms/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 5/50\n",
      "1599/1599 [==============================] - 66s 41ms/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 6/50\n",
      "1599/1599 [==============================] - 48s 30ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 7/50\n",
      "1599/1599 [==============================] - 46s 29ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 8/50\n",
      "1599/1599 [==============================] - 45s 28ms/step - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 9/50\n",
      "1599/1599 [==============================] - 48s 30ms/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 10/50\n",
      "1599/1599 [==============================] - 47s 29ms/step - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 11/50\n",
      "1599/1599 [==============================] - 47s 30ms/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 12/50\n",
      "1599/1599 [==============================] - 46s 29ms/step - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 00012: early stopping\n",
      "348 0 3814 3814 382 382\n",
      "349 3814 7602 3788 379 379\n",
      "350 7602 11403 3801 380 380\n",
      "351 11403 15276 3873 388 388\n",
      "352 15276 19269 3993 400 400\n",
      "353 19269 23346 4077 408 408\n",
      "354 23346 27511 4165 417 417\n",
      "355 27511 31665 4154 416 416\n",
      "356 31665 35900 4235 424 424\n",
      "357 35900 40120 4220 422 422\n",
      "358 40120 44422 4302 431 431\n",
      "359 44422 48771 4349 435 435\n",
      "Epoch 1/50\n",
      "1636/1636 [==============================] - 61s 36ms/step - loss: 0.1034 - val_loss: 0.0113\n",
      "Epoch 2/50\n",
      "1636/1636 [==============================] - 57s 35ms/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 3/50\n",
      "1636/1636 [==============================] - 46s 28ms/step - loss: 0.0099 - val_loss: 0.0091\n",
      "Epoch 4/50\n",
      "1636/1636 [==============================] - 46s 28ms/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 5/50\n",
      "1636/1636 [==============================] - 47s 29ms/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 6/50\n",
      "1636/1636 [==============================] - 53s 32ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 7/50\n",
      "1636/1636 [==============================] - 63s 38ms/step - loss: 0.0096 - val_loss: 0.0089\n",
      "Epoch 8/50\n",
      "1636/1636 [==============================] - 47s 29ms/step - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 9/50\n",
      "1636/1636 [==============================] - 43s 26ms/step - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 10/50\n",
      "1636/1636 [==============================] - 43s 26ms/step - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 11/50\n",
      "1636/1636 [==============================] - 46s 28ms/step - loss: 0.0095 - val_loss: 0.0091\n",
      "Epoch 12/50\n",
      "1636/1636 [==============================] - 53s 32ms/step - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 13/50\n",
      "1636/1636 [==============================] - 56s 34ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 14/50\n",
      "1636/1636 [==============================] - 42s 25ms/step - loss: 0.0094 - val_loss: 0.0089\n",
      "Epoch 00014: early stopping\n",
      "360 0 4404 4404 441 441\n",
      "361 4404 8899 4495 450 450\n",
      "362 8899 13475 4576 458 458\n",
      "363 13475 18152 4677 468 468\n",
      "364 18152 22858 4706 471 471\n",
      "365 22858 27609 4751 475 475\n",
      "366 27609 32443 4834 484 484\n",
      "367 32443 37312 4869 487 487\n",
      "368 37312 42141 4829 483 483\n",
      "369 42141 46934 4793 480 480\n",
      "370 46934 51734 4800 480 480\n",
      "371 51734 56518 4784 479 479\n",
      "Epoch 1/50\n",
      "1658/1658 [==============================] - 45s 26ms/step - loss: 0.0781 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "1658/1658 [==============================] - 45s 27ms/step - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 3/50\n",
      "1658/1658 [==============================] - 49s 30ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 4/50\n",
      "1658/1658 [==============================] - 65s 39ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 5/50\n",
      "1658/1658 [==============================] - 42s 25ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 6/50\n",
      "1658/1658 [==============================] - 43s 26ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 7/50\n",
      "1658/1658 [==============================] - 44s 27ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 8/50\n",
      "1658/1658 [==============================] - 48s 29ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 9/50\n",
      "1658/1658 [==============================] - 61s 37ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 10/50\n",
      "1658/1658 [==============================] - 51s 31ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 11/50\n",
      "1658/1658 [==============================] - 45s 27ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 12/50\n",
      "1658/1658 [==============================] - 46s 28ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 13/50\n",
      "1658/1658 [==============================] - 50s 30ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 14/50\n",
      "1658/1658 [==============================] - 70s 42ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 15/50\n",
      "1658/1658 [==============================] - 42s 25ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 16/50\n",
      "1658/1658 [==============================] - 43s 26ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 17/50\n",
      "1658/1658 [==============================] - 47s 28ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 18/50\n",
      "1658/1658 [==============================] - 51s 31ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 19/50\n",
      "1658/1658 [==============================] - 69s 42ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 20/50\n",
      "1658/1658 [==============================] - 42s 26ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 21/50\n",
      "1658/1658 [==============================] - 43s 26ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 22/50\n",
      "1658/1658 [==============================] - 47s 28ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 23/50\n",
      "1658/1658 [==============================] - 54s 33ms/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 24/50\n",
      "1658/1658 [==============================] - 65s 39ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 25/50\n",
      "1658/1658 [==============================] - 43s 26ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 26/50\n",
      "1658/1658 [==============================] - 44s 27ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 27/50\n",
      "1658/1658 [==============================] - 49s 29ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 28/50\n",
      "1658/1658 [==============================] - 62s 38ms/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 29/50\n",
      "1658/1658 [==============================] - 55s 33ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 30/50\n",
      "1658/1658 [==============================] - 43s 26ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 31/50\n",
      "1658/1658 [==============================] - 47s 28ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 32/50\n",
      "1658/1658 [==============================] - 51s 31ms/step - loss: 0.0092 - val_loss: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00032: early stopping\n",
      "372 0 4796 4796 392 318\n",
      "373 4796 9647 4851 428 387\n",
      "374 9647 14512 4865 424 414\n",
      "375 14512 19386 4874 394 392\n",
      "376 19386 24199 4813 344 340\n",
      "377 24199 28945 4746 311 368\n",
      "378 28945 33728 4783 449 347\n",
      "379 33728 38551 4823 407 310\n",
      "380 38551 43389 4838 426 332\n",
      "381 43389 48268 4879 431 341\n",
      "382 48268 53185 4917 451 366\n",
      "383 53185 58216 5031 503 374\n",
      "Epoch 1/50\n",
      "1674/1674 [==============================] - 64s 37ms/step - loss: 0.0856 - val_loss: 0.0099\n",
      "Epoch 2/50\n",
      "1674/1674 [==============================] - 44s 26ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 3/50\n",
      "1674/1674 [==============================] - 47s 28ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 4/50\n",
      "1674/1674 [==============================] - 53s 31ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 5/50\n",
      "1674/1674 [==============================] - 65s 39ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 6/50\n",
      "1674/1674 [==============================] - 43s 26ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 7/50\n",
      "1674/1674 [==============================] - 44s 26ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 8/50\n",
      "1674/1674 [==============================] - 48s 29ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 9/50\n",
      "1674/1674 [==============================] - 56s 34ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 10/50\n",
      "1674/1674 [==============================] - 61s 37ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 11/50\n",
      "1674/1674 [==============================] - 45s 27ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 12/50\n",
      "1674/1674 [==============================] - 46s 27ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 13/50\n",
      "1674/1674 [==============================] - 50s 30ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 14/50\n",
      "1674/1674 [==============================] - 67s 40ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 15/50\n",
      "1674/1674 [==============================] - 51s 30ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 16/50\n",
      "1674/1674 [==============================] - 44s 26ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 17/50\n",
      "1674/1674 [==============================] - 48s 28ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 18/50\n",
      "1674/1674 [==============================] - 54s 32ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 19/50\n",
      "1674/1674 [==============================] - 73s 44ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 00019: early stopping\n",
      "384 0 5130 5130 513 513\n",
      "385 5130 10334 5204 521 521\n",
      "386 10334 15562 5228 523 523\n",
      "387 15562 20692 5130 513 513\n",
      "388 20692 25862 5170 517 517\n",
      "389 25862 31074 5212 522 522\n",
      "390 31074 36298 5224 523 523\n",
      "391 36298 41575 5277 528 528\n",
      "392 41575 46934 5359 536 536\n",
      "393 46934 52400 5466 547 547\n",
      "394 52400 58054 5654 566 566\n",
      "395 58054 63692 5638 564 564\n",
      "Epoch 1/50\n",
      "1663/1663 [==============================] - 46s 27ms/step - loss: 0.0157 - val_loss: 0.0092\n",
      "Epoch 2/50\n",
      "1663/1663 [==============================] - 46s 28ms/step - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 3/50\n",
      "1663/1663 [==============================] - 60s 36ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 4/50\n",
      "1663/1663 [==============================] - 81s 49ms/step - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 5/50\n",
      "1663/1663 [==============================] - 45s 27ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 6/50\n",
      "1663/1663 [==============================] - 50s 30ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 7/50\n",
      "1663/1663 [==============================] - 57s 34ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 8/50\n",
      "1663/1663 [==============================] - 78s 47ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 9/50\n",
      "1663/1663 [==============================] - 44s 27ms/step - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 10/50\n",
      "1663/1663 [==============================] - 48s 29ms/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 11/50\n",
      "1663/1663 [==============================] - 57s 34ms/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 12/50\n",
      "1663/1663 [==============================] - 80s 48ms/step - loss: 0.0090 - val_loss: 0.0090\n",
      "Epoch 13/50\n",
      "1663/1663 [==============================] - 46s 27ms/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 14/50\n",
      "1663/1663 [==============================] - 47s 28ms/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 00014: early stopping\n",
      "396 0 5483 5483 549 549\n",
      "397 5483 11037 5554 556 556\n",
      "398 11037 16615 5578 558 558\n",
      "399 16615 22155 5540 554 554\n",
      "400 22155 27735 5580 558 558\n",
      "401 27735 33281 5546 555 555\n",
      "402 33281 38921 5640 564 564\n",
      "403 38921 44532 5611 561 561\n",
      "404 44532 50011 5479 548 548\n",
      "405 50011 55407 5396 540 540\n",
      "406 55407 60886 5479 548 548\n",
      "407 60886 66397 5511 551 551\n",
      "Epoch 1/50\n",
      "1679/1679 [==============================] - 78s 45ms/step - loss: 0.1595 - val_loss: 0.0565\n",
      "Epoch 2/50\n",
      "1679/1679 [==============================] - 71s 42ms/step - loss: 0.0267 - val_loss: 0.0137\n",
      "Epoch 3/50\n",
      "1679/1679 [==============================] - 50s 30ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 4/50\n",
      "1679/1679 [==============================] - 62s 37ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 5/50\n",
      "1679/1679 [==============================] - 71s 42ms/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 6/50\n",
      "1679/1679 [==============================] - 47s 28ms/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 7/50\n",
      "1679/1679 [==============================] - 49s 29ms/step - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 8/50\n",
      "1679/1679 [==============================] - 56s 33ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 9/50\n",
      "1679/1679 [==============================] - 66s 40ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 10/50\n",
      "1679/1679 [==============================] - 49s 29ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 11/50\n",
      "1679/1679 [==============================] - 47s 28ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 12/50\n",
      "1679/1679 [==============================] - 50s 30ms/step - loss: 0.0089 - val_loss: 0.0093\n",
      "Epoch 00012: early stopping\n",
      "408 0 5545 5545 555 555\n",
      "409 5545 11146 5601 560 560\n",
      "410 11146 16862 5716 572 572\n",
      "411 16862 22545 5683 569 569\n",
      "412 22545 28197 5652 566 566\n",
      "413 28197 33688 5491 549 549\n",
      "414 33688 39169 5481 548 548\n",
      "415 39169 44708 5539 554 554\n",
      "416 44708 50295 5587 559 559\n",
      "417 50295 55899 5604 561 561\n",
      "418 55899 61444 5545 555 555\n",
      "419 61444 66870 5426 543 543\n",
      "Epoch 1/50\n",
      "1709/1709 [==============================] - 58s 33ms/step - loss: 0.0745 - val_loss: 0.0110\n",
      "Epoch 2/50\n",
      "1709/1709 [==============================] - 65s 38ms/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 3/50\n",
      "1709/1709 [==============================] - 68s 40ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 4/50\n",
      "1709/1709 [==============================] - 51s 30ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 5/50\n",
      "1709/1709 [==============================] - 54s 32ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 6/50\n",
      "1709/1709 [==============================] - 55s 32ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 7/50\n",
      "1709/1709 [==============================] - 75s 44ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 8/50\n",
      "1709/1709 [==============================] - 50s 29ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 9/50\n",
      "1709/1709 [==============================] - 51s 30ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 10/50\n",
      "1709/1709 [==============================] - 54s 31ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 11/50\n",
      "1709/1709 [==============================] - 56s 33ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 12/50\n",
      "1709/1709 [==============================] - 58s 34ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 13/50\n",
      "1709/1709 [==============================] - 58s 34ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 14/50\n",
      "1709/1709 [==============================] - 48s 28ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 15/50\n",
      "1709/1709 [==============================] - 51s 30ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 16/50\n",
      "1709/1709 [==============================] - 52s 30ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 17/50\n",
      "1709/1709 [==============================] - 51s 30ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 18/50\n",
      "1709/1709 [==============================] - 56s 33ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 19/50\n",
      "1709/1709 [==============================] - 70s 41ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1709/1709 [==============================] - 65s 38ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 21/50\n",
      "1709/1709 [==============================] - 55s 32ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 22/50\n",
      "1709/1709 [==============================] - 57s 33ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 00022: early stopping\n",
      "420 0 5326 5326 533 533\n",
      "421 5326 10213 4887 489 489\n",
      "422 10213 15109 4896 490 490\n",
      "423 15109 19977 4868 487 487\n",
      "424 19977 24924 4947 495 495\n",
      "425 24924 29829 4905 491 491\n",
      "426 29829 34835 5006 501 501\n",
      "427 34835 39716 4881 488 488\n",
      "428 39716 44487 4771 477 477\n",
      "429 44487 49392 4905 491 491\n",
      "430 49392 54347 4955 496 496\n",
      "431 54347 59309 4962 497 497\n",
      "Epoch 1/50\n",
      "1750/1750 [==============================] - 57s 31ms/step - loss: 0.0467 - val_loss: 0.0112\n",
      "Epoch 2/50\n",
      "1750/1750 [==============================] - 56s 32ms/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 3/50\n",
      "1750/1750 [==============================] - 56s 32ms/step - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 4/50\n",
      "1750/1750 [==============================] - 56s 32ms/step - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 5/50\n",
      "1750/1750 [==============================] - 56s 32ms/step - loss: 0.0092 - val_loss: 0.0105\n",
      "Epoch 6/50\n",
      "1750/1750 [==============================] - 63s 36ms/step - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 7/50\n",
      "1750/1750 [==============================] - 63s 36ms/step - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 8/50\n",
      "1750/1750 [==============================] - 62s 36ms/step - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 9/50\n",
      "1750/1750 [==============================] - 61s 35ms/step - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 10/50\n",
      "1750/1750 [==============================] - 66s 38ms/step - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 11/50\n",
      "1750/1750 [==============================] - 80s 46ms/step - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 12/50\n",
      "1750/1750 [==============================] - 55s 32ms/step - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 13/50\n",
      "1750/1750 [==============================] - 58s 33ms/step - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 14/50\n",
      "1750/1750 [==============================] - 72s 41ms/step - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 15/50\n",
      "1750/1750 [==============================] - 81s 46ms/step - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 16/50\n",
      "1750/1750 [==============================] - 58s 33ms/step - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 00016: early stopping\n",
      "432 0 4997 4997 500 500\n",
      "433 4997 9894 4897 490 490\n",
      "434 9894 14726 4832 484 484\n",
      "435 14726 19521 4795 480 480\n",
      "436 19521 24426 4905 491 491\n",
      "437 24426 29403 4977 498 498\n",
      "438 29403 34445 5042 505 505\n",
      "439 34445 39646 5201 520 520\n",
      "440 39646 44780 5134 514 514\n",
      "441 44780 49651 4871 487 487\n",
      "442 49651 54342 4691 469 469\n",
      "443 54342 59094 4752 476 476\n",
      "Epoch 1/50\n",
      "1808/1808 [==============================] - 102s 55ms/step - loss: 0.0210 - val_loss: 0.0120\n",
      "Epoch 2/50\n",
      "1808/1808 [==============================] - 58s 32ms/step - loss: 0.0090 - val_loss: 0.0118\n",
      "Epoch 3/50\n",
      "1808/1808 [==============================] - 60s 33ms/step - loss: 0.0090 - val_loss: 0.0117\n",
      "Epoch 4/50\n",
      "1808/1808 [==============================] - 75s 41ms/step - loss: 0.0089 - val_loss: 0.0117\n",
      "Epoch 5/50\n",
      "1808/1808 [==============================] - 81s 45ms/step - loss: 0.0089 - val_loss: 0.0117\n",
      "Epoch 6/50\n",
      "1808/1808 [==============================] - 52s 29ms/step - loss: 0.0088 - val_loss: 0.0117\n",
      "Epoch 7/50\n",
      "1808/1808 [==============================] - 60s 33ms/step - loss: 0.0088 - val_loss: 0.0117\n",
      "Epoch 8/50\n",
      "1808/1808 [==============================] - 96s 53ms/step - loss: 0.0088 - val_loss: 0.0117\n",
      "Epoch 9/50\n",
      "1808/1808 [==============================] - 62s 34ms/step - loss: 0.0088 - val_loss: 0.0118\n",
      "Epoch 10/50\n",
      "1808/1808 [==============================] - 62s 35ms/step - loss: 0.0087 - val_loss: 0.0118\n",
      "Epoch 11/50\n",
      "1808/1808 [==============================] - 109s 60ms/step - loss: 0.0087 - val_loss: 0.0117\n",
      "Epoch 00011: early stopping\n",
      "444 0 4676 4676 468 468\n",
      "445 4676 9427 4751 475 475\n",
      "446 9427 14033 4606 461 461\n",
      "447 14033 18442 4409 441 441\n",
      "448 18442 22551 4109 411 411\n",
      "449 22551 26543 3992 400 400\n",
      "450 26543 30781 4238 424 424\n",
      "451 30781 34836 4055 406 406\n",
      "452 34836 38742 3906 391 391\n",
      "453 38742 42655 3913 392 392\n",
      "454 42655 46661 4006 401 401\n",
      "455 46661 50652 3991 399 399\n",
      "Epoch 1/50\n",
      "1885/1885 [==============================] - 62s 32ms/step - loss: 0.0947 - val_loss: 0.0138\n",
      "Epoch 2/50\n",
      "1885/1885 [==============================] - 76s 40ms/step - loss: 0.0097 - val_loss: 0.0131\n",
      "Epoch 3/50\n",
      "1885/1885 [==============================] - 98s 52ms/step - loss: 0.0093 - val_loss: 0.0128\n",
      "Epoch 4/50\n",
      "1885/1885 [==============================] - 60s 32ms/step - loss: 0.0092 - val_loss: 0.0128\n",
      "Epoch 5/50\n",
      "1885/1885 [==============================] - 74s 39ms/step - loss: 0.0092 - val_loss: 0.0128\n",
      "Epoch 6/50\n",
      "1885/1885 [==============================] - 102s 54ms/step - loss: 0.0092 - val_loss: 0.0128\n",
      "Epoch 7/50\n",
      "1885/1885 [==============================] - 57s 30ms/step - loss: 0.0091 - val_loss: 0.0128\n",
      "Epoch 8/50\n",
      "1885/1885 [==============================] - 66s 35ms/step - loss: 0.0092 - val_loss: 0.0127\n",
      "Epoch 9/50\n",
      "1885/1885 [==============================] - 112s 59ms/step - loss: 0.0091 - val_loss: 0.0128\n",
      "Epoch 10/50\n",
      "1885/1885 [==============================] - 59s 31ms/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 11/50\n",
      "1885/1885 [==============================] - 63s 34ms/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 12/50\n",
      "1885/1885 [==============================] - 100s 53ms/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 13/50\n",
      "1885/1885 [==============================] - 79s 42ms/step - loss: 0.0091 - val_loss: 0.0128\n",
      "Epoch 14/50\n",
      "1885/1885 [==============================] - 66s 35ms/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 15/50\n",
      "1885/1885 [==============================] - 76s 40ms/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 00015: early stopping\n",
      "456 0 3933 3933 394 394\n",
      "457 3933 7767 3834 384 384\n",
      "458 7767 11368 3601 360 360\n",
      "459 11368 15033 3665 367 367\n",
      "460 15033 18777 3744 375 375\n",
      "461 18777 22591 3814 382 382\n",
      "462 22591 26384 3793 380 380\n",
      "463 26384 30073 3689 369 369\n",
      "464 30073 33845 3772 378 378\n",
      "465 33845 37574 3729 373 373\n",
      "466 37574 41253 3679 368 346\n",
      "467 41253 44824 3571 357 293\n",
      "Epoch 1/50\n",
      "1961/1961 [==============================] - 97s 48ms/step - loss: 0.0442 - val_loss: 0.0138\n",
      "Epoch 2/50\n",
      "1961/1961 [==============================] - 60s 31ms/step - loss: 0.0095 - val_loss: 0.0132\n",
      "Epoch 3/50\n",
      "1961/1961 [==============================] - 74s 38ms/step - loss: 0.0093 - val_loss: 0.0131\n",
      "Epoch 4/50\n",
      "1961/1961 [==============================] - 115s 59ms/step - loss: 0.0093 - val_loss: 0.0131\n",
      "Epoch 5/50\n",
      "1961/1961 [==============================] - 60s 31ms/step - loss: 0.0092 - val_loss: 0.0131\n",
      "Epoch 6/50\n",
      "1961/1961 [==============================] - 85s 44ms/step - loss: 0.0092 - val_loss: 0.0131\n",
      "Epoch 7/50\n",
      "1961/1961 [==============================] - 94s 48ms/step - loss: 0.0092 - val_loss: 0.0131\n",
      "Epoch 8/50\n",
      "1961/1961 [==============================] - 63s 32ms/step - loss: 0.0092 - val_loss: 0.0131\n",
      "Epoch 9/50\n",
      "1961/1961 [==============================] - 92s 47ms/step - loss: 0.0092 - val_loss: 0.0131\n",
      "Epoch 00009: early stopping\n",
      "468 0 3373 3373 266 217\n",
      "469 3373 6722 3349 301 166\n",
      "470 6722 9940 3218 299 196\n",
      "471 9940 13203 3263 327 167\n",
      "472 13203 16581 3378 338 169\n",
      "473 16581 19912 3331 333 183\n",
      "474 19912 23206 3294 303 200\n",
      "475 23206 26458 3252 317 210\n",
      "476 26458 29680 3222 308 182\n",
      "477 29680 33000 3320 332 219\n",
      "478 33000 36475 3475 348 190\n",
      "479 36475 40015 3540 354 174\n",
      "Epoch 1/50\n",
      "2048/2048 [==============================] - 75s 35ms/step - loss: 0.0971 - val_loss: 0.0138\n",
      "Epoch 2/50\n",
      "2048/2048 [==============================] - 65s 32ms/step - loss: 0.0094 - val_loss: 0.0137\n",
      "Epoch 3/50\n",
      "2048/2048 [==============================] - 121s 59ms/step - loss: 0.0094 - val_loss: 0.0137\n",
      "Epoch 4/50\n",
      "2048/2048 [==============================] - 60s 29ms/step - loss: 0.0094 - val_loss: 0.0137\n",
      "Epoch 5/50\n",
      "2048/2048 [==============================] - 62s 30ms/step - loss: 0.0094 - val_loss: 0.0137\n",
      "Epoch 6/50\n",
      "2048/2048 [==============================] - 85s 42ms/step - loss: 0.0093 - val_loss: 0.0136\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 95s 46ms/step - loss: 0.0093 - val_loss: 0.0136\n",
      "Epoch 8/50\n",
      "2048/2048 [==============================] - 55s 27ms/step - loss: 0.0092 - val_loss: 0.0135\n",
      "Epoch 9/50\n",
      "2048/2048 [==============================] - 62s 30ms/step - loss: 0.0092 - val_loss: 0.0135\n",
      "Epoch 10/50\n",
      "2048/2048 [==============================] - 91s 44ms/step - loss: 0.0091 - val_loss: 0.0133\n",
      "Epoch 11/50\n",
      "2048/2048 [==============================] - 81s 40ms/step - loss: 0.0090 - val_loss: 0.0133\n",
      "Epoch 12/50\n",
      "2048/2048 [==============================] - 56s 27ms/step - loss: 0.0090 - val_loss: 0.0133\n",
      "Epoch 13/50\n",
      "2048/2048 [==============================] - 65s 32ms/step - loss: 0.0090 - val_loss: 0.0133\n",
      "Epoch 14/50\n",
      "2048/2048 [==============================] - 105s 51ms/step - loss: 0.0089 - val_loss: 0.0133\n",
      "Epoch 15/50\n",
      "2048/2048 [==============================] - 59s 29ms/step - loss: 0.0089 - val_loss: 0.0133\n",
      "Epoch 16/50\n",
      "2048/2048 [==============================] - 57s 28ms/step - loss: 0.0089 - val_loss: 0.0133\n",
      "Epoch 17/50\n",
      "2048/2048 [==============================] - 67s 33ms/step - loss: 0.0089 - val_loss: 0.0133\n",
      "Epoch 18/50\n",
      "2048/2048 [==============================] - 106s 52ms/step - loss: 0.0087 - val_loss: 0.0134\n",
      "Epoch 19/50\n",
      "2048/2048 [==============================] - 56s 27ms/step - loss: 0.0087 - val_loss: 0.0135\n",
      "Epoch 00019: early stopping\n",
      "480 0 3615 3615 362 362\n",
      "481 3615 7267 3652 366 366\n",
      "482 7267 10963 3696 370 370\n",
      "483 10963 14752 3789 379 379\n",
      "484 14752 18573 3821 382 382\n",
      "485 18573 22420 3847 385 385\n",
      "486 22420 26349 3929 393 393\n",
      "487 26349 30289 3940 394 394\n",
      "488 30289 34220 3931 393 393\n",
      "489 34220 38087 3867 387 387\n",
      "490 38087 41939 3852 386 386\n",
      "491 41939 45798 3859 386 386\n",
      "Epoch 1/50\n",
      "2115/2115 [==============================] - 63s 29ms/step - loss: 0.0790 - val_loss: 0.0137\n",
      "Epoch 2/50\n",
      "2115/2115 [==============================] - 87s 41ms/step - loss: 0.0108 - val_loss: 0.0125\n",
      "Epoch 3/50\n",
      "2115/2115 [==============================] - 84s 39ms/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 4/50\n",
      "2115/2115 [==============================] - 55s 26ms/step - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 5/50\n",
      "2115/2115 [==============================] - 62s 29ms/step - loss: 0.0100 - val_loss: 0.0121\n",
      "Epoch 6/50\n",
      "2115/2115 [==============================] - 94s 44ms/step - loss: 0.0100 - val_loss: 0.0121\n",
      "Epoch 7/50\n",
      "2115/2115 [==============================] - 75s 36ms/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 8/50\n",
      "2115/2115 [==============================] - 59s 28ms/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 9/50\n",
      "2115/2115 [==============================] - 73s 34ms/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "2115/2115 [==============================] - 103s 49ms/step - loss: 0.0098 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "2115/2115 [==============================] - 55s 26ms/step - loss: 0.0098 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "2115/2115 [==============================] - 61s 29ms/step - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 13/50\n",
      "2115/2115 [==============================] - 93s 44ms/step - loss: 0.0098 - val_loss: 0.0120\n",
      "Epoch 14/50\n",
      "2115/2115 [==============================] - 77s 36ms/step - loss: 0.0098 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "2115/2115 [==============================] - 56s 26ms/step - loss: 0.0097 - val_loss: 0.0120\n",
      "Epoch 16/50\n",
      "2115/2115 [==============================] - 65s 31ms/step - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 00016: early stopping\n",
      "492 0 3752 3752 376 376\n",
      "493 3752 7472 3720 372 372\n",
      "494 7472 11235 3763 377 377\n",
      "495 11235 15000 3765 377 377\n",
      "496 15000 18830 3830 383 383\n",
      "497 18830 22729 3899 390 390\n",
      "498 22729 26566 3837 384 384\n",
      "499 26566 30412 3846 385 385\n",
      "500 30412 34221 3809 381 381\n",
      "501 34221 37918 3697 370 370\n",
      "502 37918 41643 3725 373 373\n",
      "503 41643 45407 3764 377 377\n",
      "Epoch 1/50\n",
      "2186/2186 [==============================] - 109s 49ms/step - loss: 0.1116 - val_loss: 0.0114\n",
      "Epoch 2/50\n",
      "2186/2186 [==============================] - 56s 25ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 3/50\n",
      "2186/2186 [==============================] - 62s 28ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 4/50\n",
      "2186/2186 [==============================] - 88s 40ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 5/50\n",
      "2186/2186 [==============================] - 82s 38ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 6/50\n",
      "2186/2186 [==============================] - 58s 27ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 7/50\n",
      "2186/2186 [==============================] - 68s 31ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 8/50\n",
      "2186/2186 [==============================] - 116s 53ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 9/50\n",
      "2186/2186 [==============================] - 55s 25ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 10/50\n",
      "2186/2186 [==============================] - 61s 28ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 11/50\n",
      "2186/2186 [==============================] - 81s 37ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 12/50\n",
      "2186/2186 [==============================] - 93s 42ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 00012: early stopping\n",
      "504 0 3844 3844 385 385\n",
      "505 3844 7668 3824 383 383\n",
      "506 7668 11494 3826 383 383\n",
      "507 11494 15301 3807 381 381\n",
      "508 15301 19118 3817 382 382\n",
      "509 19118 22952 3834 384 384\n",
      "510 22952 26816 3864 387 387\n",
      "511 26816 30699 3883 389 389\n",
      "512 30699 34610 3911 391 390\n",
      "513 34610 38514 3904 391 391\n",
      "514 38514 42364 3850 385 385\n",
      "515 42364 46208 3844 385 385\n",
      "Epoch 1/50\n",
      "2238/2238 [==============================] - 61s 26ms/step - loss: 0.0757 - val_loss: 0.0104\n",
      "Epoch 2/50\n",
      "2238/2238 [==============================] - 70s 31ms/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 3/50\n",
      "2238/2238 [==============================] - 113s 51ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 4/50\n",
      "2238/2238 [==============================] - 58s 26ms/step - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 5/50\n",
      "2238/2238 [==============================] - 63s 28ms/step - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 6/50\n",
      "2238/2238 [==============================] - 91s 40ms/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 7/50\n",
      "2238/2238 [==============================] - 88s 39ms/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 8/50\n",
      "2238/2238 [==============================] - 59s 26ms/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 9/50\n",
      "2238/2238 [==============================] - 68s 30ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 10/50\n",
      "2238/2238 [==============================] - 117s 52ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 00010: early stopping\n",
      "516 0 3791 3791 379 379\n",
      "517 3791 7567 3776 378 378\n",
      "518 7567 11362 3795 380 380\n",
      "519 11362 15205 3843 385 385\n",
      "520 15205 19065 3860 386 386\n",
      "521 19065 22925 3860 386 386\n",
      "522 22925 26785 3860 386 386\n",
      "523 26785 30638 3853 386 386\n",
      "524 30638 34486 3848 385 385\n",
      "525 34486 38330 3844 385 385\n",
      "526 38330 42186 3856 386 386\n",
      "527 42186 46033 3847 385 385\n",
      "Epoch 1/50\n",
      "2244/2244 [==============================] - 60s 26ms/step - loss: 0.1085 - val_loss: 0.0091\n",
      "Epoch 2/50\n",
      "2244/2244 [==============================] - 69s 31ms/step - loss: 0.0116 - val_loss: 0.0082\n",
      "Epoch 3/50\n",
      "2244/2244 [==============================] - 112s 50ms/step - loss: 0.0111 - val_loss: 0.0081\n",
      "Epoch 4/50\n",
      "2244/2244 [==============================] - 57s 26ms/step - loss: 0.0111 - val_loss: 0.0081\n",
      "Epoch 5/50\n",
      "2244/2244 [==============================] - 66s 29ms/step - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 6/50\n",
      "2244/2244 [==============================] - 106s 47ms/step - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 7/50\n",
      "2244/2244 [==============================] - 66s 29ms/step - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 8/50\n",
      "2244/2244 [==============================] - 63s 28ms/step - loss: 0.0109 - val_loss: 0.0081\n",
      "Epoch 9/50\n",
      "2244/2244 [==============================] - 99s 44ms/step - loss: 0.0109 - val_loss: 0.0082\n",
      "Epoch 10/50\n",
      "2244/2244 [==============================] - 78s 35ms/step - loss: 0.0109 - val_loss: 0.0081\n",
      "Epoch 00010: early stopping\n",
      "528 0 3795 3795 380 380\n",
      "529 3795 7542 3747 375 375\n",
      "530 7542 11269 3727 373 373\n",
      "531 11269 14980 3711 371 371\n",
      "532 14980 18606 3626 363 363\n",
      "533 18606 22225 3619 362 362\n",
      "534 22225 25790 3565 357 357\n",
      "535 25790 29294 3504 351 351\n",
      "536 29294 32732 3438 344 344\n",
      "537 32732 36154 3422 343 343\n",
      "538 36154 39573 3419 342 342\n",
      "539 39573 42861 3288 329 329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2210/2210 [==============================] - 63s 28ms/step - loss: 0.0930 - val_loss: 0.0102\n",
      "Epoch 2/50\n",
      "2210/2210 [==============================] - 88s 40ms/step - loss: 0.0119 - val_loss: 0.0085\n",
      "Epoch 3/50\n",
      "2210/2210 [==============================] - 85s 39ms/step - loss: 0.0113 - val_loss: 0.0083\n",
      "Epoch 4/50\n",
      "2210/2210 [==============================] - 58s 26ms/step - loss: 0.0112 - val_loss: 0.0083\n",
      "Epoch 5/50\n",
      "2210/2210 [==============================] - 66s 30ms/step - loss: 0.0111 - val_loss: 0.0083\n",
      "Epoch 6/50\n",
      "2210/2210 [==============================] - 108s 49ms/step - loss: 0.0111 - val_loss: 0.0083\n",
      "Epoch 7/50\n",
      "2210/2210 [==============================] - 60s 27ms/step - loss: 0.0110 - val_loss: 0.0083\n",
      "Epoch 8/50\n",
      "2210/2210 [==============================] - 61s 28ms/step - loss: 0.0110 - val_loss: 0.0083\n",
      "Epoch 9/50\n",
      "2210/2210 [==============================] - 89s 40ms/step - loss: 0.0110 - val_loss: 0.0083\n",
      "Epoch 10/50\n",
      "2210/2210 [==============================] - 87s 39ms/step - loss: 0.0110 - val_loss: 0.0083\n",
      "Epoch 00010: early stopping\n",
      "540 0 3283 3283 329 329\n",
      "541 3283 6542 3259 326 326\n",
      "542 6542 9682 3140 314 314\n",
      "543 9682 12500 2818 282 282\n",
      "544 12500 15083 2583 259 259\n",
      "545 15083 17678 2595 260 260\n",
      "546 17678 20177 2499 250 250\n",
      "547 20177 22514 2337 234 234\n",
      "548 22514 24937 2423 243 243\n",
      "549 24937 27545 2608 261 261\n",
      "550 27545 30240 2695 270 270\n",
      "551 30240 32959 2719 272 272\n",
      "Epoch 1/50\n",
      "2168/2168 [==============================] - 59s 27ms/step - loss: 0.0208 - val_loss: 0.0096\n",
      "Epoch 2/50\n",
      "2168/2168 [==============================] - 66s 31ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      "Epoch 3/50\n",
      "2168/2168 [==============================] - 108s 50ms/step - loss: 0.0112 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "2168/2168 [==============================] - 57s 26ms/step - loss: 0.0111 - val_loss: 0.0094\n",
      "Epoch 5/50\n",
      "2168/2168 [==============================] - 60s 28ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 6/50\n",
      "2168/2168 [==============================] - 72s 33ms/step - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 7/50\n",
      "2168/2168 [==============================] - 106s 49ms/step - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 8/50\n",
      "2168/2168 [==============================] - 56s 26ms/step - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 00008: early stopping\n",
      "552 0 2790 2790 279 199\n",
      "553 2790 5635 2845 285 134\n",
      "554 5635 8519 2884 289 136\n",
      "555 8519 11330 2811 281 185\n",
      "556 11330 14129 2799 280 163\n",
      "557 14129 16979 2850 285 173\n",
      "558 16979 19827 2848 285 153\n",
      "559 19827 22706 2879 288 178\n",
      "560 22706 25670 2964 297 154\n",
      "561 25670 28696 3026 303 189\n",
      "562 28696 31633 2937 294 172\n",
      "563 31633 34488 2855 286 188\n",
      "Epoch 1/50\n",
      "2118/2118 [==============================] - 68s 31ms/step - loss: 0.0879 - val_loss: 0.0119\n",
      "Epoch 2/50\n",
      "2118/2118 [==============================] - 109s 51ms/step - loss: 0.0123 - val_loss: 0.0100\n",
      "Epoch 3/50\n",
      "2118/2118 [==============================] - 53s 25ms/step - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 4/50\n",
      "2118/2118 [==============================] - 61s 29ms/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 5/50\n",
      "2118/2118 [==============================] - 92s 44ms/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 6/50\n",
      "2118/2118 [==============================] - 75s 35ms/step - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 7/50\n",
      "2118/2118 [==============================] - 58s 27ms/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 8/50\n",
      "2118/2118 [==============================] - 75s 35ms/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 9/50\n",
      "2118/2118 [==============================] - 98s 46ms/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 10/50\n",
      "2118/2118 [==============================] - 56s 26ms/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 00010: early stopping\n",
      "564 0 2866 2866 287 287\n",
      "565 2866 5658 2792 280 280\n",
      "566 5658 8531 2873 288 288\n",
      "567 8531 11452 2921 292 292\n",
      "568 11452 14374 2922 293 293\n",
      "569 14374 17355 2981 298 298\n",
      "570 17355 20342 2987 299 299\n",
      "571 20342 23350 3008 301 301\n",
      "572 23350 26329 2979 298 298\n",
      "573 26329 29300 2971 297 297\n",
      "574 29300 32257 2957 296 296\n",
      "575 32257 35171 2914 292 292\n",
      "Epoch 1/50\n",
      "2050/2050 [==============================] - 67s 32ms/step - loss: 0.0202 - val_loss: 0.0102\n",
      "Epoch 2/50\n",
      "2050/2050 [==============================] - 108s 53ms/step - loss: 0.0112 - val_loss: 0.0100\n",
      "Epoch 3/50\n",
      "2050/2050 [==============================] - 53s 26ms/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 4/50\n",
      "2050/2050 [==============================] - 57s 28ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 5/50\n",
      "2050/2050 [==============================] - 76s 37ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 6/50\n",
      "2050/2050 [==============================] - 93s 45ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 7/50\n",
      "2050/2050 [==============================] - 53s 26ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 8/50\n",
      "2050/2050 [==============================] - 58s 28ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 9/50\n",
      "2050/2050 [==============================] - 88s 43ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 10/50\n",
      "2050/2050 [==============================] - 84s 41ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 00010: early stopping\n",
      "576 0 2891 2891 289 289\n",
      "577 2891 5692 2801 280 280\n",
      "578 5692 8380 2688 269 269\n",
      "579 8380 11144 2764 277 277\n",
      "580 11144 13892 2748 275 275\n",
      "581 13892 16638 2746 275 275\n",
      "582 16638 19441 2803 281 281\n",
      "583 19441 22265 2824 283 283\n",
      "584 22265 25111 2846 285 285\n",
      "585 25111 27952 2841 284 284\n",
      "586 27952 30733 2781 278 278\n",
      "587 30733 33534 2801 280 280\n",
      "Epoch 1/50\n",
      "1970/1970 [==============================] - 56s 28ms/step - loss: 0.0994 - val_loss: 0.0139\n",
      "Epoch 2/50\n",
      "1970/1970 [==============================] - 60s 31ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 3/50\n",
      "1970/1970 [==============================] - 100s 51ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 4/50\n",
      "1970/1970 [==============================] - 58s 29ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 5/50\n",
      "1970/1970 [==============================] - 53s 27ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 6/50\n",
      "1970/1970 [==============================] - 61s 31ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 7/50\n",
      "1970/1970 [==============================] - 103s 52ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 8/50\n",
      "1970/1970 [==============================] - 60s 31ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 00008: early stopping\n",
      "588 0 2771 2771 277 277\n",
      "589 2771 5551 2780 278 278\n",
      "590 5551 8361 2810 281 281\n",
      "591 8361 11151 2790 279 279\n",
      "592 11151 13929 2778 278 278\n",
      "593 13929 16690 2761 276 276\n",
      "594 16690 19516 2826 283 283\n",
      "595 19516 22323 2807 281 281\n",
      "596 22323 25149 2826 283 283\n",
      "597 25149 27985 2836 284 284\n",
      "598 27985 30862 2877 288 288\n",
      "599 30862 33748 2886 289 289\n",
      "Epoch 1/50\n",
      "1876/1876 [==============================] - 58s 30ms/step - loss: 0.0241 - val_loss: 0.0100\n",
      "Epoch 2/50\n",
      "1876/1876 [==============================] - 84s 45ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 3/50\n",
      "1876/1876 [==============================] - 70s 37ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 4/50\n",
      "1876/1876 [==============================] - 50s 27ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 5/50\n",
      "1876/1876 [==============================] - 58s 31ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 6/50\n",
      "1876/1876 [==============================] - 95s 51ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 7/50\n",
      "1876/1876 [==============================] - 57s 30ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 8/50\n",
      "1876/1876 [==============================] - 51s 27ms/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 00008: early stopping\n",
      "600 0 2931 2931 293 293\n",
      "601 2931 5853 2922 293 293\n",
      "602 5853 8822 2969 297 297\n",
      "603 8822 11788 2966 297 297\n",
      "604 11788 14775 2987 299 299\n",
      "605 14775 17785 3010 301 301\n",
      "606 17785 20814 3029 303 303\n",
      "607 20814 23867 3053 306 306\n",
      "608 23867 26928 3061 306 306\n",
      "609 26928 29968 3040 304 304\n",
      "610 29968 32998 3030 303 303\n",
      "611 32998 36066 3068 307 307\n",
      "Epoch 1/50\n",
      "1773/1773 [==============================] - 69s 38ms/step - loss: 0.1714 - val_loss: 0.0086\n",
      "Epoch 2/50\n",
      "1773/1773 [==============================] - 91s 51ms/step - loss: 0.0110 - val_loss: 0.0084\n",
      "Epoch 3/50\n",
      "1773/1773 [==============================] - 47s 26ms/step - loss: 0.0108 - val_loss: 0.0084\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773/1773 [==============================] - 66s 37ms/step - loss: 0.0108 - val_loss: 0.0083\n",
      "Epoch 5/50\n",
      "1773/1773 [==============================] - 94s 53ms/step - loss: 0.0108 - val_loss: 0.0084\n",
      "Epoch 6/50\n",
      "1773/1773 [==============================] - 46s 26ms/step - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 7/50\n",
      "1773/1773 [==============================] - 55s 31ms/step - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 8/50\n",
      "1773/1773 [==============================] - 81s 45ms/step - loss: 0.0107 - val_loss: 0.0083\n",
      "Epoch 9/50\n",
      "1773/1773 [==============================] - 71s 40ms/step - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 00009: early stopping\n",
      "612 0 3057 3057 306 306\n",
      "613 3057 6135 3078 308 308\n",
      "614 6135 9176 3041 304 304\n",
      "615 9176 12218 3042 305 305\n",
      "616 12218 15265 3047 305 305\n",
      "617 15265 18322 3057 306 306\n",
      "618 18322 21358 3036 304 304\n",
      "619 21358 24406 3048 305 305\n",
      "620 24406 27440 3034 304 304\n",
      "621 27440 30483 3043 305 305\n",
      "622 30483 33531 3048 305 305\n",
      "623 33531 36584 3053 306 306\n",
      "Epoch 1/50\n",
      "1677/1677 [==============================] - 48s 28ms/step - loss: 0.1089 - val_loss: 0.0086\n",
      "Epoch 2/50\n",
      "1677/1677 [==============================] - 53s 32ms/step - loss: 0.0106 - val_loss: 0.0081\n",
      "Epoch 3/50\n",
      "1677/1677 [==============================] - 82s 49ms/step - loss: 0.0105 - val_loss: 0.0081\n",
      "Epoch 4/50\n",
      "1677/1677 [==============================] - 65s 39ms/step - loss: 0.0104 - val_loss: 0.0082\n",
      "Epoch 5/50\n",
      "1677/1677 [==============================] - 46s 27ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 6/50\n",
      "1677/1677 [==============================] - 52s 31ms/step - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 7/50\n",
      "1677/1677 [==============================] - 80s 48ms/step - loss: 0.0103 - val_loss: 0.0083\n",
      "Epoch 8/50\n",
      "1677/1677 [==============================] - 73s 44ms/step - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 9/50\n",
      "1677/1677 [==============================] - 44s 26ms/step - loss: 0.0102 - val_loss: 0.0082\n",
      "Epoch 10/50\n",
      "1677/1677 [==============================] - 47s 28ms/step - loss: 0.0101 - val_loss: 0.0083\n",
      "Epoch 00010: early stopping\n",
      "624 0 3023 3023 208 303\n",
      "625 3023 6036 3013 199 302\n",
      "626 6036 8984 2948 192 295\n",
      "627 8984 11950 2966 225 297\n",
      "628 11950 14920 2970 237 297\n",
      "629 14920 17854 2934 214 294\n",
      "630 17854 20687 2833 142 284\n",
      "631 20687 23505 2818 193 282\n",
      "632 23505 26364 2859 218 286\n",
      "633 26364 29233 2869 250 287\n",
      "634 29233 32091 2858 275 286\n",
      "635 32091 34957 2866 261 287\n",
      "Epoch 1/50\n",
      "1617/1617 [==============================] - 61s 37ms/step - loss: 0.0907 - val_loss: 0.0083\n",
      "Epoch 2/50\n",
      "1617/1617 [==============================] - 93s 58ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 3/50\n",
      "1617/1617 [==============================] - 42s 26ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 4/50\n",
      "1617/1617 [==============================] - 44s 27ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 5/50\n",
      "1617/1617 [==============================] - 50s 31ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 6/50\n",
      "1617/1617 [==============================] - 68s 42ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 7/50\n",
      "1617/1617 [==============================] - 84s 52ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 8/50\n",
      "1617/1617 [==============================] - 42s 26ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 9/50\n",
      "1617/1617 [==============================] - 46s 28ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 10/50\n",
      "1617/1617 [==============================] - 54s 33ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 11/50\n",
      "1617/1617 [==============================] - 83s 51ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 12/50\n",
      "1617/1617 [==============================] - 68s 42ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 13/50\n",
      "1617/1617 [==============================] - 43s 26ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 14/50\n",
      "1617/1617 [==============================] - 47s 29ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 15/50\n",
      "1617/1617 [==============================] - 54s 33ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 16/50\n",
      "1617/1617 [==============================] - 88s 55ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 00016: early stopping\n",
      "636 0 2887 2887 181 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilian\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\lilian\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637 2887 5775 2888 165 0\n",
      "638 5775 8679 2904 193 0\n",
      "639 8679 11544 2865 180 0\n",
      "640 11544 14422 2878 196 0\n",
      "641 14422 17292 2870 179 0\n",
      "642 17292 20159 2867 167 0\n",
      "643 20159 23018 2859 158 0\n",
      "644 23018 25872 2854 159 0\n",
      "645 25872 28723 2851 167 0\n",
      "646 28723 31556 2833 170 0\n",
      "647 31556 34414 2858 171 0\n",
      "Epoch 1/50\n",
      "1573/1573 [==============================] - 51s 31ms/step - loss: 0.0727 - val_loss: 0.0086\n",
      "Epoch 2/50\n",
      "1573/1573 [==============================] - 43s 28ms/step - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 3/50\n",
      "1573/1573 [==============================] - 48s 30ms/step - loss: 0.0096 - val_loss: 0.0078\n",
      "Epoch 4/50\n",
      "1573/1573 [==============================] - 63s 40ms/step - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 5/50\n",
      "1573/1573 [==============================] - 92s 59ms/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 6/50\n",
      "1573/1573 [==============================] - 41s 26ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 7/50\n",
      "1573/1573 [==============================] - 43s 28ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 8/50\n",
      "1573/1573 [==============================] - 47s 30ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 9/50\n",
      "1573/1573 [==============================] - 62s 40ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 10/50\n",
      "1573/1573 [==============================] - 90s 57ms/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 11/50\n",
      "1573/1573 [==============================] - 40s 26ms/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 12/50\n",
      "1573/1573 [==============================] - 42s 27ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 13/50\n",
      "1573/1573 [==============================] - 47s 30ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 14/50\n",
      "1573/1573 [==============================] - 63s 40ms/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 15/50\n",
      "1573/1573 [==============================] - 85s 54ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 16/50\n",
      "1573/1573 [==============================] - 47s 30ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 17/50\n",
      "1573/1573 [==============================] - 49s 31ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 18/50\n",
      "1573/1573 [==============================] - 57s 36ms/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 19/50\n",
      "1573/1573 [==============================] - 91s 58ms/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 20/50\n",
      "1573/1573 [==============================] - 45s 28ms/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 00020: early stopping\n",
      "648 0 2836 2836 284 284\n",
      "649 2836 5660 2824 283 283\n",
      "650 5660 8494 2834 284 284\n",
      "651 8494 11308 2814 282 282\n",
      "652 11308 14154 2846 285 285\n",
      "653 14154 16998 2844 285 285\n",
      "654 16998 19860 2862 287 287\n",
      "655 19860 22704 2844 285 285\n",
      "656 22704 25535 2831 283 283\n",
      "657 25535 28383 2848 285 285\n",
      "658 28383 31270 2887 289 289\n",
      "659 31270 34171 2901 290 290\n",
      "Epoch 1/50\n",
      "1548/1548 [==============================] - 47s 29ms/step - loss: 0.2197 - val_loss: 0.0083\n",
      "Epoch 2/50\n",
      "1548/1548 [==============================] - 52s 34ms/step - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 3/50\n",
      "1548/1548 [==============================] - 89s 58ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 4/50\n",
      "1548/1548 [==============================] - 52s 33ms/step - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 5/50\n",
      "1548/1548 [==============================] - 66s 42ms/step - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 6/50\n",
      "1548/1548 [==============================] - 79s 51ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 7/50\n",
      "1548/1548 [==============================] - 74s 48ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 8/50\n",
      "1548/1548 [==============================] - 50s 32ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 9/50\n",
      "1548/1548 [==============================] - 55s 36ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 10/50\n",
      "1548/1548 [==============================] - 86s 56ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 11/50\n",
      "1548/1548 [==============================] - 76s 49ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 12/50\n",
      "1548/1548 [==============================] - 46s 30ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 13/50\n",
      "1548/1548 [==============================] - 52s 34ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 14/50\n",
      "1548/1548 [==============================] - 82s 53ms/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 00014: early stopping\n",
      "660 0 2896 2896 290 290\n",
      "661 2896 5806 2910 291 291\n",
      "662 5806 8723 2917 292 292\n",
      "663 8723 11576 2853 286 286\n",
      "664 11576 14391 2815 282 282\n",
      "665 14391 17107 2716 272 272\n",
      "666 17107 19889 2782 279 279\n",
      "667 19889 22693 2804 281 281\n",
      "668 22693 25502 2809 281 281\n",
      "669 25502 28320 2818 282 282\n",
      "670 28320 31087 2767 277 277\n",
      "671 31087 33892 2805 281 281\n",
      "Epoch 1/50\n",
      "1510/1510 [==============================] - 77s 49ms/step - loss: 0.1360 - val_loss: 0.0106\n",
      "Epoch 2/50\n",
      "1510/1510 [==============================] - 48s 32ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 3/50\n",
      "1510/1510 [==============================] - 68s 45ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 4/50\n",
      "1510/1510 [==============================] - 92s 61ms/step - loss: 0.0090 - val_loss: 0.0086\n",
      "Epoch 5/50\n",
      "1510/1510 [==============================] - 54s 36ms/step - loss: 0.0090 - val_loss: 0.0086\n",
      "Epoch 6/50\n",
      "1510/1510 [==============================] - 70s 46ms/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 7/50\n",
      "1510/1510 [==============================] - 112s 74ms/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 8/50\n",
      "1510/1510 [==============================] - 49s 33ms/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 9/50\n",
      "1510/1510 [==============================] - 54s 36ms/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 10/50\n",
      "1510/1510 [==============================] - 75s 50ms/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 11/50\n",
      "1510/1510 [==============================] - 103s 68ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 12/50\n",
      "1510/1510 [==============================] - 49s 33ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 13/50\n",
      "1510/1510 [==============================] - 57s 38ms/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 14/50\n",
      "1510/1510 [==============================] - 88s 58ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 15/50\n",
      "1510/1510 [==============================] - 82s 54ms/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 16/50\n",
      "1510/1510 [==============================] - 52s 34ms/step - loss: 0.0088 - val_loss: 0.0086\n",
      "Epoch 17/50\n",
      "1510/1510 [==============================] - 74s 49ms/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 00017: early stopping\n",
      "672 0 2793 2793 280 280\n",
      "673 2793 5543 2750 275 275\n",
      "674 5543 8302 2759 276 276\n",
      "675 8302 11059 2757 276 276\n",
      "676 11059 13805 2746 275 275\n",
      "677 13805 16578 2773 278 278\n"
     ]
    }
   ],
   "source": [
    "for retrain_idx in range(42):\n",
    "    X = Z_eff.iloc[train_start[retrain_idx]:train_end[retrain_idx],:]\n",
    "    X_idx = X.apply(pd.Series.nunique) != 1\n",
    "    X = X.loc[:,X_idx]\n",
    "    X_val = Z_eff.iloc[val_start[retrain_idx]:val_end[retrain_idx],:]\n",
    "    X_test = Z_eff.iloc[test_start[retrain_idx]:test_end[retrain_idx],:]\n",
    "    X_val = X_val.loc[:,X_idx]\n",
    "    X_test = X_test.loc[:,X_idx]\n",
    "    y =R_eff.iloc[train_start[retrain_idx]:train_end[retrain_idx],:]\n",
    "    y_val = R_eff.iloc[val_start[retrain_idx]:val_end[retrain_idx],:]\n",
    "    y_test = R_eff.iloc[test_start[retrain_idx]:test_end[retrain_idx],:] #since it is time series data\n",
    "    yorg = R_org_eff.iloc[train_start[retrain_idx]:train_end[retrain_idx],:]\n",
    "    yorg_val = R_org_eff.iloc[val_start[retrain_idx]:val_end[retrain_idx],:]\n",
    "    yorg_test=R_org_eff.iloc[test_start[retrain_idx]:test_end[retrain_idx],:]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(8,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(4,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(2,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adamax',loss='mse')\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "    history = model.fit(x=X,y=y,validation_data=(X_val,y_val), batch_size=256, epochs=50,verbose=1,callbacks=[early_stop])\n",
    "    preds = model.predict(X_test).flatten()\n",
    "    y_org_test = yorg_test[0].to_list()\n",
    "    R_pred.iloc[test_start[retrain_idx]:test_end[retrain_idx],:]=pd.DataFrame(preds)\n",
    "    \n",
    "    for t in range(t_test_start[retrain_idx], t_test_end[retrain_idx]):\n",
    "        month_start = group_ind.iloc[t][0] - group_ind.iloc[t_test_start[retrain_idx]][0]\n",
    "        month_end = group_ind.iloc[t+1][0] - group_ind.iloc[t_test_start[retrain_idx]][0]\n",
    "        preds_month = preds[month_start:month_end]\n",
    "        yorg_month = y_org_test[month_start:month_end]\n",
    "        list_buy = [i for i, val in enumerate(preds_month) if val > np.quantile(preds_month,.9)]\n",
    "        list_sell = [i for i, val in enumerate(preds_month) if val < np.quantile(preds_month,.1)]\n",
    "        print(t,month_start,month_end,len(preds_month),len(list_buy),len(list_sell))\n",
    "        portf_ret_nn_test.append(np.mean([yorg_month[i] for i in list_buy]) - np.mean([yorg_month[i] for i in list_sell]))\n",
    "    loss.append(min(history.history['val_loss']))\n",
    "    model_list.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.52207574489709"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(portf_ret_nn_test)/np.nanstd(portf_ret_nn_test)*np.sqrt(12)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Finance.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
